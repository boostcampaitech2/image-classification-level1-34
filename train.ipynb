{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ac077b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/train/train.csv\")\n",
    "df = df.drop([\"race\"],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70b1b4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리\n",
    "\n",
    "#여자 -> 남자\n",
    "ids = [\"006359\", \"006360\", \"006361\", \"006362\", \"006363\", \"006364\"]\n",
    "\n",
    "df.loc[df[df[\"id\"].isin(ids)].index, \"gender\"] = \"male\"\n",
    "\n",
    "#남자 -> 여자\n",
    "ids = [\"001498-1\", \"004432\"]\n",
    "df.loc[df[df[\"id\"].isin(ids)].index, \"gender\"] = \"female\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07434f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2700 2700\n",
      "2700 2700\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 데이터 유효성 검사.\n",
    "\n",
    "import glob\n",
    "\n",
    "train_peoples_path = \"./data/train/images/*\"\n",
    "people_paths = glob.glob(train_peoples_path)\n",
    "people_names = [name.split(\"/\")[-1] for name in people_paths ]\n",
    "\n",
    "#길이 비교\n",
    "print(len(people_names), len(df[\"path\"]))\n",
    "#중복 문자열 존재하는지 비교\n",
    "print(len(set(people_names)), len(set(df[\"path\"])))\n",
    "#불일치 문자열 존재하는지 체크\n",
    "print(len(set(people_names) - set(df[\"path\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0505d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "raw_data = df\n",
    "for train_index, test_index in split.split(raw_data, raw_data[\"age\"]):\n",
    "    strat_train_set = raw_data.loc[train_index]\n",
    "    strat_test_set = raw_data.loc[test_index]\n",
    "\n",
    "train_df = strat_train_set\n",
    "valid_df = strat_test_set\n",
    "# strat_train_set[\"age\"].hist()\n",
    "# plt.show()\n",
    "# strat_test_set[\"age\"].hist()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "801d8595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labeling(df, folder_path):\n",
    "    temp = pd.DataFrame()\n",
    "    \n",
    "    path_list = []\n",
    "    full_path_list = [] \n",
    "    state_list = []\n",
    "    for path in df[\"path\"]:\n",
    "        #사람 폴더에서 이미지 경로 받기.\n",
    "        imgs = glob.glob(folder_path + \"/\" + path + \"/*\")\n",
    "        \n",
    "        path_list.extend([path]*7)\n",
    "        full_path_list.extend([full_path for full_path in imgs])\n",
    "        state_list.extend([full_path.split(\"/\")[-1].split(\".\")[0] for full_path in imgs])\n",
    "  \n",
    "    temp[\"path\"] = path_list\n",
    "    temp[\"img_path\"] = full_path_list\n",
    "    temp[\"state\"] = state_list\n",
    "    return temp\n",
    "\n",
    "mask_state_train_df = labeling(train_df, \"data/train/images\")  \n",
    "\n",
    "mask_state_valid_df = labeling(valid_df, \"data/train/images\")\n",
    "\n",
    "def merge_df(df, mask_state_df):\n",
    "    return_df = pd.merge(df, mask_state_df, how= \"outer\", on = \"path\")\n",
    "    # print(return_df)\n",
    "    return_df.loc[return_df.query(\"state == 'incorrect_mask'\").index, \"state\"] = \"incorrect\"\n",
    "\n",
    "    # 라벨링\n",
    "    return_df[\"label\"] = 0\n",
    "    return_df.loc[return_df.query(\"state == 'incorrect'\").index, \"label\"] += 6\n",
    "    return_df.loc[return_df.query(\"state == 'normal'\").index, \"label\"] += 12\n",
    "\n",
    "    return_df.loc[return_df.query(\"gender == 'female'\").index, \"label\"] += 3\n",
    "\n",
    "    return_df.loc[return_df.query(\"30 <= age < 60 \").index, \"label\"] += 1\n",
    "    return_df.loc[return_df.query(\"age == 60 \").index, \"label\"] += 2\n",
    "\n",
    "\n",
    "    # valid_df = return_df.iloc[200:]\n",
    "    # return_df = return_df.iloc[:200]\n",
    "\n",
    "    return_df[\"c_gender\"] = 0\n",
    "    return_df.loc[return_df.query(\"gender == 'male'\").index, \"c_gender\"] = 1\n",
    "\n",
    "    return_df[\"c_state\"] = 0\n",
    "    return_df.loc[return_df.query(\"state == 'incorrect'\").index, \"c_state\"] = 1\n",
    "    return_df.loc[return_df.query(\"state == 'normal'\").index, \"c_state\"] = 2\n",
    "\n",
    "    return_df[\"c_age\"] = 0\n",
    "    return_df.loc[return_df.query(\"30 <= age < 60 \").index, \"c_age\"] = 1\n",
    "    return_df.loc[return_df.query(\"age == 60 \").index, \"c_age\"] = 2\n",
    "    \n",
    "    \n",
    "    label_dict = {0: \"마스크쓴 남성 청년\",\n",
    "              1: \"마스크쓴 남성 중년\",\n",
    "              2: \"마스크쓴 남성 노년\",\n",
    "              3: \"마스크쓴 여성 청년\",\n",
    "              4: \"마스크쓴 여성 중년\",\n",
    "              5: \"마스크쓴 여성 노년\",\n",
    "              \n",
    "              6: \"잘못쓴 남성 청년\",\n",
    "              7: \"잘못쓴 남성 중년\",\n",
    "              8: \"잘못쓴 남성 노년\",\n",
    "              9: \"잘못쓴 여성 청년\",\n",
    "              10: \"잘못쓴 여성 중년\",\n",
    "              11: \"잘못쓴 여성 노년\",\n",
    "              \n",
    "              12: \"안쓴 남성 청년\",\n",
    "              13: \"안쓴 남성 중년\",\n",
    "              14: \"안쓴 남성 노년\",\n",
    "              15: \"안쓴 여성 청년\",\n",
    "              16: \"안쓴 여성 중년\",\n",
    "              17: \"안쓴 여성 노년\",\n",
    "    }\n",
    "    return_df[\"label_check\"] = return_df[\"label\"].replace(label_dict)\n",
    "    return return_df\n",
    "\n",
    "train_df = merge_df(train_df, mask_state_train_df)\n",
    " \n",
    "valid_df = merge_df(valid_df, mask_state_valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "123cb97b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>state</th>\n",
       "      <th>label_check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>male</td>\n",
       "      <td>18</td>\n",
       "      <td>mask3</td>\n",
       "      <td>마스크쓴 남성 청년</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1356</th>\n",
       "      <td>female</td>\n",
       "      <td>20</td>\n",
       "      <td>mask1</td>\n",
       "      <td>마스크쓴 여성 청년</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2358</th>\n",
       "      <td>female</td>\n",
       "      <td>25</td>\n",
       "      <td>mask5</td>\n",
       "      <td>마스크쓴 여성 청년</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>female</td>\n",
       "      <td>60</td>\n",
       "      <td>incorrect</td>\n",
       "      <td>잘못쓴 여성 노년</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  age      state label_check\n",
       "752     male   18      mask3  마스크쓴 남성 청년\n",
       "1356  female   20      mask1  마스크쓴 여성 청년\n",
       "2358  female   25      mask5  마스크쓴 여성 청년\n",
       "119   female   60  incorrect   잘못쓴 여성 노년"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.sample(4)[[\"gender\",\"age\",\"state\",\"label_check\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77967703",
   "metadata": {},
   "source": [
    "# 이미지 데이터셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7990da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "import albumentations as A\n",
    "import albumentations.pytorch\n",
    "import cv2\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.CenterCrop((450, 250)),\n",
    "#     transforms.ToTensor()\n",
    "#     ,\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "# ])\n",
    "\n",
    "# # Declare an augmentation pipeline\n",
    "album_transform = A.Compose([\n",
    "    A.CenterCrop(width=300, height=350),\n",
    "#     A.Resize(256,256),\n",
    "    A.Resize(320,320),\n",
    "#     A.ToGray(p=1),\n",
    "    A.\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "#     A.RandomBrightnessContrast(p=0.5),\n",
    "#     A.HueSaturationValue(),\n",
    "    A.pytorch.transforms.ToTensorV2()\n",
    "])\n",
    "\n",
    "valid_transform = A.Compose([\n",
    "    A.CenterCrop(width=300, height=350),\n",
    "#     A.Resize(256,256),\n",
    "    A.Resize(320,320),\n",
    "    A.ToGray(p=1),\n",
    "#     A.HorizontalFlip(p=0.5),\n",
    "#     A.RandomBrightnessContrast(p=0.5),\n",
    "#     A.HueSaturationValue(),\n",
    "    A.pytorch.transforms.ToTensorV2()\n",
    "])\n",
    "\n",
    "class Maskset(Dataset):\n",
    "    def __init__(self, df, transform, label = \"label\"):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.label = label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        raw_image = cv2.imread(self.df[\"img_path\"].iloc[idx])\n",
    "        image = cv2.cvtColor(raw_image, cv2.COLOR_BGR2RGB)\n",
    "        augmented = self.transform(image=image) \n",
    "#         transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        x = augmented['image']\n",
    "        y = torch.tensor(self.df[self.label].iloc[idx])\n",
    "        return (x/255).type(torch.float), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03f330c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "import torch\n",
    "\n",
    "labes_unique, counts = np.unique(train_df[\"label\"], return_counts = True)\n",
    "class_weights = [sum(counts) / c for c in counts]\n",
    "example_weights = [class_weights[e] for e in train_df[\"label\"]]\n",
    "sampler = WeightedRandomSampler(example_weights, len(train_df[\"label\"]))\n",
    "# class_weights\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "train_set_dict = {}\n",
    "valid_set_dict = {}\n",
    "train_loader_dict = {}\n",
    "valid_loader_dict = {}\n",
    "\n",
    "for label in [\"label\", \"c_age\", \"c_gender\", \"c_state\"]:    \n",
    "    train_set_dict[label] = Maskset(train_df, album_transform, label)\n",
    "    valid_set_dict[label] = Maskset(valid_df, valid_transform, label)\n",
    "\n",
    "    train_loader_dict[label] = DataLoader(train_set_dict[label], num_workers=4, batch_size=BATCH_SIZE, drop_last = True, sampler = sampler)\n",
    "    valid_loader_dict[label] = DataLoader(valid_set_dict[label], num_workers=4, batch_size=BATCH_SIZE, drop_last = True, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bef10dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(train_loader.dataset), len(valid_loader.dataset))\n",
    "print(len(train_loader_dict[\"label\"].dataset), len(valid_loader_dict[\"label\"].dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36213027",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms.ToPILImage()(next(iter(train_loader_dict[\"label\"]))[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1300a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms.ToPILImage()(next(iter(valid_loader_dict[\"label\"]))[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81751beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from facenet_pytorch import InceptionResnetV1\n",
    "\n",
    "# # For a model pretrained on VGGFace2\n",
    "# model = InceptionResnetV1(pretrained='vggface2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba74669e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# age\n",
    "import timm\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "from tqdm.notebook import tqdm \n",
    "\n",
    "import math\n",
    "\n",
    "from torch import optim\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "NUM_EPOCH = 5\n",
    "LEARNING_RATE = 0.0003\n",
    "\n",
    "def train_model(model, train_loader, valid_loader):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     device = \"cpu\"\n",
    "    \n",
    "    model.to(device)\n",
    "\n",
    "    dataloaders = {\n",
    "        \"train\" : train_loader,\n",
    "        \"test\" : valid_loader\n",
    "    }\n",
    "\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()   # 비용 함수에 소프트맥스 함수 포함되어져 있음.\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr= LEARNING_RATE)\n",
    "#     scheduler = optim.lr_scheduler.LambdaLR(optimizer=optimizer, lr_lambda=lambda epoch: 0.95 ** epoch)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=0)\n",
    "    best_test_accuracy = 0.\n",
    "    best_test_loss = 9999.\n",
    "\n",
    "    for epoch in range(NUM_EPOCH):\n",
    "        for phase in [\"train\", \"test\"]:\n",
    "            running_loss = 0.\n",
    "            running_acc = 0.\n",
    "            epoch_f1 = 0\n",
    "            n_iter = 0\n",
    "            if phase == \"train\":\n",
    "                model.train() # 네트워크 모델을 train 모드로 두어 gradient을 계산하고, 여러 sub module (배치 정규화, 드롭아웃 등)이 train mode로 작동할 수 있도록 함\n",
    "            elif phase == \"test\":\n",
    "                model.eval() # 네트워크 모델을 eval 모드 두어 여러 sub module들이 eval mode로 작동할 수 있게 함\n",
    "\n",
    "            for ind, (images, labels) in enumerate(tqdm(dataloaders[phase])):\n",
    "\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad() # parameter gradient를 업데이트 전 초기화함\n",
    "                with torch.set_grad_enabled(phase == \"train\"): # train 모드일 시에는 gradient를 계산하고, 아닐 때는 gradient를 계산하지 않아 연산량 최소화\n",
    "                    logits = model(images)\n",
    "                    _, preds = torch.max(logits, 1) # 모델에서 linear 값으로 나오는 예측 값 ([0.9,1.2, 3.2,0.1,-0.1,...])을 최대 output index를 찾아 예측 레이블([2])로 변경함  \n",
    "                    loss = loss_fn(logits, labels)\n",
    "\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward() # 모델의 예측 값과 실제 값의 CrossEntropy 차이를 통해 gradient 계산\n",
    "                        optimizer.step() # 계산된 gradient를 가지고 모델 업데이트\n",
    "                        scheduler.step() \n",
    "\n",
    "                running_loss += loss.item() * images.size(0) # 한 Batch에서의 loss 값 저장\n",
    "                running_acc += torch.sum(preds == labels) # 한 Batch에서의 Accuracy 값 저장\n",
    "                epoch_f1 += f1_score(labels.cpu().numpy(), preds.cpu().numpy(), average='macro')\n",
    "                n_iter += 1\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_acc / len(dataloaders[phase].dataset)\n",
    "            epoch_f1 = epoch_f1/n_iter\n",
    "            \n",
    "            print(f\"현재 epoch-{epoch}의 {phase}-데이터 셋에서 평균 Loss : {epoch_loss:.3f}, 평균 Accuracy : {epoch_acc:.3f}, 평균 f1 : {epoch_f1:.4f}\\n\\n\")\n",
    "\n",
    "        if phase == \"test\" and best_test_accuracy < epoch_acc: # phase가 test일 때, best accuracy 계산\n",
    "            best_test_accuracy = epoch_acc\n",
    "        if phase == \"test\" and best_test_loss > epoch_loss: # phase가 test일 때, best loss 계산\n",
    "            best_test_loss = epoch_loss\n",
    "\n",
    "    print(\"학습 종료!\")\n",
    "    print(f\"최고 accuracy : {best_test_accuracy}, 최고 낮은 loss : {best_test_loss}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45997b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):   \n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "\n",
    "def initialize_model(model_name, feature_extract, num_classes=7, task='fer2013', use_pretrained=True):\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"vgg\":\n",
    "    \n",
    "        model_ft = models.vgg19_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        if task == 'fer2013':\n",
    "            model_ft.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
    "        else:\n",
    "            model_ft.classifier[6] = nn.Linear(num_ftrs, 128)\n",
    "        input_size = 224\n",
    "    return model_ft, input_size\n",
    "\n",
    "\n",
    "class PretrainedMT(nn.Module):\n",
    "    \"\"\"Pretrained Pytorch neural network module for multitask learning\"\"\"\n",
    "\n",
    "    def __init__(self, model_name='resnet', feature_extract=True, use_pretrained=True):\n",
    "        super(PretrainedMT, self).__init__()\n",
    "        self.conv_base, input_size = initialize_model(model_name, feature_extract, num_classes=None,\n",
    "                                                      task='utk', use_pretrained=use_pretrained)\n",
    "        # self.output_age = nn.Linear(128, 3)\n",
    "        # self.output_gender = nn.Linear(128, 2)\n",
    "        # self.output_race = nn.Linear(128, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_base(x)\n",
    "        # age = self.output_age(x)\n",
    "        # gender = self.output_gender(x)\n",
    "        # race = self.output_race(x)\n",
    "        return x #age, gender, race\n",
    "\n",
    "vgg_model = PretrainedMT(model_name='vgg')\n",
    "# vgg_model = train_model(vgg_model, train_loader_dict[label],  valid_loader_dict[label])\n",
    "\n",
    "state_dict = torch.load(\"vgg.pth\")\n",
    "for state in ['output_age.weight', 'output_age.bias', 'output_gender.weight', 'output_gender.bias', 'output_race.weight', 'output_race.bias']:\n",
    "    del state_dict[state]\n",
    "# state_dict.keys()\n",
    "\n",
    "vgg_model.load_state_dict(state_dict)\n",
    "\n",
    "import math\n",
    "vgg_model.last = torch.nn.Linear(128, 3, bias = True )\n",
    "torch.nn.init.xavier_uniform_(vgg_model.last.weight)\n",
    "stdv = 1. / math.sqrt(vgg_model.last.weight.size(1))\n",
    "vgg_model.last.bias.data.uniform_(-stdv, stdv)\n",
    "vgg_model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57977e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model(next(iter(train_loader_dict[label]))[0].to(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9582c5e3-b121-4251-8b59-1a8295efb288",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"c_age\"\n",
    "vgg_model = train_model(vgg_model, train_loader_dict[label],  valid_loader_dict[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08c30d0-bdf7-4979-834e-73283c126d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ddd089-a165-4d76-9ecb-d6c38ed021d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"c_age\"\n",
    "eff_model = timm.create_model('efficientnetv2_rw_m', pretrained=True, num_classes= 3)\n",
    "eff_model = train_model(eff_model, train_loader_dict[label],  valid_loader_dict[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79409387-00c1-4702-beea-a195dcb87ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"c_state\"\n",
    "eff_state_model = timm.create_model('efficientnetv2_rw_m', pretrained=True, num_classes= 3)\n",
    "eff_state_model = train_model(eff_state_model, train_loader_dict[label],  valid_loader_dict[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727b0b5b-7da3-4f45-8086-c18cf83c6098",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"c_gender\"\n",
    "eff_gende_model = timm.create_model('efficientnetv2_rw_m', pretrained=True, num_classes= 2)\n",
    "eff_gende_model = train_model(eff_gende_model, train_loader_dict[label],  valid_loader_dict[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d1ef9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bcf266",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"c_age\"\n",
    "age_model = timm.create_model('resnext50_32x4d', pretrained=True, num_classes= 3)\n",
    "age_model = train_model(age_model, train_loader_dict[label],  valid_loader_dict[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0636ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "# print(now)          # 2015-04-19 12:11:32.669083\n",
    "nowDate = now.strftime('%m%d_%H%M')\n",
    "print(nowDate)      # 2015-04-19\n",
    "torch.save(age_model, nowDate + \"age_resnext.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a645204-bad7-4054-8ae8-3b0d74204d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"c_state\"\n",
    "eff_model = timm.create_model('efficientnetv2_rw_m', pretrained=True, num_classes= 2)\n",
    "eff_model = train_model(eff_model, train_loader_dict[label],  valid_loader_dict[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832791e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"c_state\"\n",
    "state_model = timm.create_model('resnext50_32x4d', pretrained=True, num_classes= 3)\n",
    "state_model = train_model(state_model, train_loader_dict[label],  valid_loader_dict[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d193cb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"c_gender\"\n",
    "gender_model = timm.create_model('resnext50_32x4d', pretrained=True, num_classes= 2)\n",
    "gender_model = train_model(gender_model, train_loader_dict[label],  valid_loader_dict[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18568b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\n",
    "\n",
    "test_dir = '/opt/ml/data/eval'\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_paths, transform):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    \n",
    "    \n",
    "submission = pd.read_csv(os.path.join(test_dir, 'info.csv'))\n",
    "image_dir = os.path.join(test_dir, 'images')\n",
    "image_paths = [os.path.join(image_dir, img_id) for img_id in submission.ImageID]\n",
    "\n",
    "dataset = TestDataset(image_paths, valid_transform)\n",
    "loader = DataLoader(dataset, batch_size = 64 ,shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2dd3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = gender_model\n",
    "model.eval()\n",
    "\n",
    "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "all_predictions = []\n",
    "for images in loader:\n",
    "    with torch.no_grad():\n",
    "        images = images.to(\"cuda\")\n",
    "        pred = model(images)\n",
    "        pred = pred.argmax(dim=-1)\n",
    "        all_predictions.extend(pred.cpu().numpy())\n",
    "\n",
    "submission['gender'] = all_predictions\n",
    "\n",
    "# # 제출할 파일을 저장합니다.\n",
    "# submission.to_csv('submission.csv', index=False)\n",
    "# print('test inference is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb78bdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = age_model\n",
    "model.eval()\n",
    "\n",
    "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "all_predictions = []\n",
    "for images in loader:\n",
    "    with torch.no_grad():\n",
    "        images = images.to(\"cuda\")\n",
    "        pred = model(images)\n",
    "        pred = pred.argmax(dim=-1)\n",
    "        #_, preds = torch.max(logits, 1)\n",
    "        all_predictions.extend(pred.cpu().numpy())\n",
    "\n",
    "submission['age'] = all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64afcc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = state_model\n",
    "model.eval()\n",
    "\n",
    "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "all_predictions = []\n",
    "for images in loader:\n",
    "    with torch.no_grad():\n",
    "        images = images.to(\"cuda\")\n",
    "        pred = model(images)\n",
    "        pred = pred.argmax(dim=-1)\n",
    "        all_predictions.extend(pred.cpu().numpy())\n",
    "\n",
    "submission['state'] = all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a007cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9ccb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[\"ans\"] = 0\n",
    "submission.loc[submission.query(\"state == 1\").index, \"ans\"] += 6\n",
    "submission.loc[submission.query(\"state == 2\").index, \"ans\"] += 12\n",
    "\n",
    "submission.loc[submission.query(\"gender == 0\").index, \"ans\"] += 3\n",
    "\n",
    "submission.loc[submission.query(\"age == 1\").index, \"ans\"] += 1\n",
    "submission.loc[submission.query(\"age == 2 \").index, \"ans\"] += 2\n",
    "\n",
    "\n",
    "# train_df[\"label\"] = 0\n",
    "# train_df.loc[train_df.query(\"state == 'incorrect'\").index, \"label\"] += 6\n",
    "# train_df.loc[train_df.query(\"state == 'normal'\").index, \"label\"] += 12\n",
    "\n",
    "# train_df.loc[train_df.query(\"gender == 'female'\").index, \"label\"] += 3\n",
    "\n",
    "# train_df.loc[train_df.query(\"30 <= age < 60 \").index, \"label\"] += 1\n",
    "# train_df.loc[train_df.query(\"age == 60 \").index, \"label\"] += 2\n",
    "\n",
    "\n",
    "\n",
    "# train_df[\"c_gender\"] = 0\n",
    "# train_df.loc[train_df.query(\"gender == 'male'\").index, \"c_gender\"] = 1\n",
    "\n",
    "# train_df[\"c_state\"] = 0\n",
    "# train_df.loc[train_df.query(\"state == 'incorrect'\").index, \"c_state\"] = 1\n",
    "# train_df.loc[train_df.query(\"state == 'normal'\").index, \"c_state\"] = 2\n",
    "\n",
    "# train_df[\"c_age\"] = 0\n",
    "# train_df.loc[train_df.query(\"30 <= age < 60 \").index, \"c_age\"] = 1\n",
    "# train_df.loc[train_df.query(\"age == 60 \").index, \"c_age\"] = 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605d1992",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b605fd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[[\"ImageID\", \"ans\"]].to_csv(\"submission_5.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0293fc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model('resnext50_32x4d', pretrained=True, num_classes=18)\n",
    "\n",
    "# model = models.resnext50_32x4d(pretrained=True)\n",
    "# out_features = model.fc.out_features\n",
    "# model.last = nn.Linear(out_features, 18)\n",
    "# torch.nn.init.xavier_uniform_(model.last.weight)\n",
    "# stdv = 1. / math.sqrt(model.last.weight.size(1))\n",
    "# model.last.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "dataloaders = {\n",
    "    \"train\" : train_loader_dict[\"label\"],\n",
    "    \"test\" : valid_loader_dict[\"label\"]\n",
    "}\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()   # 비용 함수에 소프트맥스 함수 포함되어져 있음.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr= LEARNING_RATE)\n",
    "\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer=optimizer, lr_lambda=lambda epoch: 0.95 ** epoch)\n",
    "\n",
    "best_test_accuracy = 0.\n",
    "best_test_loss = 9999.\n",
    "\n",
    "for epoch in range(NUM_EPOCH):\n",
    "    \n",
    "    for phase in [\"train\", \"test\"]:\n",
    "        running_loss = 0.\n",
    "        running_acc = 0.\n",
    "        if phase == \"train\":\n",
    "            model.train() # 네트워크 모델을 train 모드로 두어 gradient을 계산하고, 여러 sub module (배치 정규화, 드롭아웃 등)이 train mode로 작동할 수 있도록 함\n",
    "        elif phase == \"test\":\n",
    "            model.eval() # 네트워크 모델을 eval 모드 두어 여러 sub module들이 eval mode로 작동할 수 있게 함\n",
    "\n",
    "        for ind, (images, labels) in enumerate(tqdm(dataloaders[phase])):\n",
    "\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad() # parameter gradient를 업데이트 전 초기화함\n",
    "\n",
    "            with torch.set_grad_enabled(phase == \"train\"): # train 모드일 시에는 gradient를 계산하고, 아닐 때는 gradient를 계산하지 않아 연산량 최소화\n",
    "                logits = model(images)\n",
    "                _, preds = torch.max(logits, 1) # 모델에서 linear 값으로 나오는 예측 값 ([0.9,1.2, 3.2,0.1,-0.1,...])을 최대 output index를 찾아 예측 레이블([2])로 변경함  \n",
    "\n",
    "                loss = loss_fn(logits, labels)\n",
    "\n",
    "                if phase == \"train\":\n",
    "                    loss.backward() # 모델의 예측 값과 실제 값의 CrossEntropy 차이를 통해 gradient 계산\n",
    "                    optimizer.step() # 계산된 gradient를 가지고 모델 업데이트\n",
    "                    scheduler.step() \n",
    "\n",
    "            running_loss += loss.item() * images.size(0) # 한 Batch에서의 loss 값 저장\n",
    "            running_acc += torch.sum(preds == labels) # 한 Batch에서의 Accuracy 값 저장\n",
    "\n",
    "    # 한 epoch이 모두 종료되었을 때,\n",
    "    epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "    epoch_acc = running_acc / len(dataloaders[phase].dataset)\n",
    "\n",
    "    print(f\"현재 epoch-{epoch}의 {phase}-데이터 셋에서 평균 Loss : {epoch_loss:.3f}, 평균 Accuracy : {epoch_acc:.3f}\")\n",
    "\n",
    "    if phase == \"test\" and best_test_accuracy < epoch_acc: # phase가 test일 때, best accuracy 계산\n",
    "        best_test_accuracy = epoch_acc\n",
    "    if phase == \"test\" and best_test_loss > epoch_loss: # phase가 test일 때, best loss 계산\n",
    "        best_test_loss = epoch_loss\n",
    "\n",
    "print(\"학습 종료!\")\n",
    "print(f\"최고 accuracy : {best_test_accuracy}, 최고 낮은 loss : {best_test_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147692aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983f278b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\n",
    "\n",
    "test_dir = '/opt/ml/data/eval'\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_paths, transform):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    \n",
    "    \n",
    "submission = pd.read_csv(os.path.join(test_dir, 'info.csv'))\n",
    "image_dir = os.path.join(test_dir, 'images')\n",
    "image_paths = [os.path.join(image_dir, img_id) for img_id in submission.ImageID]\n",
    "\n",
    "dataset = TestDataset(image_paths, transform)\n",
    "loader = DataLoader(dataset, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "all_predictions = []\n",
    "for images in loader:\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        pred = model(images)\n",
    "        pred = pred.argmax(dim=-1)\n",
    "        all_predictions.extend(pred.cpu().numpy())\n",
    "submission['ans'] = all_predictions\n",
    "\n",
    "# 제출할 파일을 저장합니다.\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print('test inference is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6e305d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = Image.open(\"data/train/images/000001_female_Asian_45/mask1.jpg\")\n",
    "\n",
    "input_tensor = transform(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch.to(\"cuda\"))\n",
    "    \n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7dff61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(EPOCH):   # 데이터셋을 수차례 반복합니다.\n",
    "\n",
    "#     # TRAINING\n",
    "    \n",
    "#     train_epoch_loss = 0\n",
    "#     train_epoch_acc = 0\n",
    "#     model.train()        \n",
    "    \n",
    "#     for X_train_batch, y_train_batch in train_loader:\n",
    "        \n",
    "#         X_train_batch, y_train_batch = X_train_batch.to(device), y_train_batch.to(device)\n",
    "#         print(y_train_batch)\n",
    "#         optimizer.zero_grad()\n",
    "        \n",
    "#         y_train_pred = model(X_train_batch)\n",
    "# #       print(y_train_pred)\n",
    "#         train_loss = criterion(y_train_pred, y_train_batch)\n",
    "# #         train_acc = multi_acc(y_train_pred, y_train_batch)\n",
    "        \n",
    "#         train_loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "# #         print(train_loss.item())\n",
    "# #         print(type(train_loss))\n",
    "\n",
    "#         train_epoch_loss += train_loss.item()\n",
    "#         train_epoch_acc += train_acc.item()\n",
    "#         break\n",
    "    \n",
    "#     # VALIDATION    \n",
    "#     with torch.no_grad():\n",
    "        \n",
    "#         val_epoch_loss = 0\n",
    "#         val_epoch_acc = 0\n",
    "        \n",
    "#         model.eval()\n",
    "#         for X_val_batch, y_val_batch in valid_loader:\n",
    "#             X_val_batch, y_val_batch = X_val_batch.to(device), y_val_batch.to(device)\n",
    "            \n",
    "#             y_val_pred = model(X_val_batch)\n",
    "                        \n",
    "#             val_loss = criterion(y_val_pred, y_val_batch)\n",
    "#             val_acc = multi_acc(y_val_pred, y_val_batch)\n",
    "            \n",
    "#             val_epoch_loss += val_loss.item()\n",
    "#             val_epoch_acc += val_acc.item()\n",
    "    \n",
    "#     loss_stats['train'].append(train_epoch_loss/len(train_loader))\n",
    "#     loss_stats['val'].append(val_epoch_loss/len(valid_loader))\n",
    "#     accuracy_stats['train'].append(train_epoch_acc/len(train_loader))\n",
    "#     accuracy_stats['val'].append(val_epoch_acc/len(valid_loader))\n",
    "                              \n",
    "#     print(f'Epoch {epoch+0:03}: | Train Loss: {train_epoch_loss/len(train_loader):.5f} | Val Loss: {val_epoch_loss/len(valid_loader):.5f} | Train Acc: {train_epoch_acc/len(train_loader):.3f}| Val Acc: {val_epoch_acc/len(valid_loader):.3f}')\n",
    "\n",
    "\n",
    "# print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa931ae-d4df-4076-90ca-70861cb9b943",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
